// ---------------------------------------------------------
// This file was generated by parol.
// It is not intended for manual editing and changes will be
// lost after next build.
// ---------------------------------------------------------

use parol_runtime::collection_literals::collection;
use parol_runtime::lr_parser::{LR1State, LRAction, LRParseTable, LRParser, LRProduction};
use parol_runtime::once_cell::sync::Lazy;
#[allow(unused_imports)]
use parol_runtime::parser::{ParseTreeType, ParseType, Production, Trans};
use parol_runtime::{ParolError, ParseTree, TerminalIndex};
use parol_runtime::{TokenStream, Tokenizer};
use std::path::Path;

use crate::list_grammar::ListGrammar;
use crate::list_grammar_trait::ListGrammarAuto;

use parol_runtime::lexer::tokenizer::{
    ERROR_TOKEN, NEW_LINE_TOKEN, UNMATCHABLE_TOKEN, WHITESPACE_TOKEN,
};

pub const TERMINALS: &[&str; 8] = &[
    /* 0 */ UNMATCHABLE_TOKEN,
    /* 1 */ UNMATCHABLE_TOKEN,
    /* 2 */ UNMATCHABLE_TOKEN,
    /* 3 */ UNMATCHABLE_TOKEN,
    /* 4 */ UNMATCHABLE_TOKEN,
    /* 5 */ r",",
    /* 6 */ r"0|[1-9][0-9]*",
    /* 7 */ ERROR_TOKEN,
];

pub const TERMINAL_NAMES: &[&str; 8] = &[
    /* 0 */ "EndOfInput",
    /* 1 */ "Newline",
    /* 2 */ "Whitespace",
    /* 3 */ "LineComment",
    /* 4 */ "BlockComment",
    /* 5 */ "Comma",
    /* 6 */ "Num",
    /* 7 */ "Error",
];

/* SCANNER_0: "INITIAL" */
const SCANNER_0: (&[&str; 5], &[TerminalIndex; 2]) = (
    &[
        /* 0 */ UNMATCHABLE_TOKEN,
        /* 1 */ NEW_LINE_TOKEN,
        /* 2 */ WHITESPACE_TOKEN,
        /* 3 */ r"(//.*(\r\n|\r|\n|$))",
        /* 4 */ UNMATCHABLE_TOKEN,
    ],
    &[5 /* Comma */, 6 /* Num */],
);

pub const NON_TERMINALS: &[&str; 5] = &[
    /* 0 */ "Items",
    /* 1 */ "ItemsList",
    /* 2 */ "List",
    /* 3 */ "ListOpt",
    /* 4 */ "Num",
];

static PARSE_TABLE: Lazy<LRParseTable> = Lazy::new(|| {
    LRParseTable::new(vec![
        // State 0
        LR1State {
            actions: collection! {
                0 /* '<$>' */ => LRAction::Reduce(3 /*ListOpt*/, 2),
                6 /* '0|[1-9][0-9]*' */ => LRAction::Shift(1),
            },
            gotos: collection! {
                0 /* Items */ => 2,
                3 /* ListOpt */ => 3,
                4 /* Num */ => 4,
            },
        },
        // State 1
        LR1State {
            actions: collection! {
                0 /* '<$>' */ => LRAction::Reduce(4 /*Num*/, 6),
                5 /* ',' */ => LRAction::Reduce(4 /*Num*/, 6),
            },
            gotos: collection! {},
        },
        // State 2
        LR1State {
            actions: collection! {
                0 /* '<$>' */ => LRAction::Reduce(3 /*ListOpt*/, 1),
            },
            gotos: collection! {},
        },
        // State 3
        LR1State {
            actions: collection! {
                0 /* '<$>' */ => LRAction::Accept,
            },
            gotos: collection! {},
        },
        // State 4
        LR1State {
            actions: collection! {
                0 /* '<$>' */ => LRAction::Reduce(1 /*ItemsList*/, 5),
                5 /* ',' */ => LRAction::Reduce(1 /*ItemsList*/, 5),
            },
            gotos: collection! {
                1 /* ItemsList */ => 5,
            },
        },
        // State 5
        LR1State {
            actions: collection! {
                0 /* '<$>' */ => LRAction::Reduce(0 /*Items*/, 3),
                5 /* ',' */ => LRAction::Shift(6),
            },
            gotos: collection! {},
        },
        // State 6
        LR1State {
            actions: collection! {
                6 /* '0|[1-9][0-9]*' */ => LRAction::Shift(1),
            },
            gotos: collection! {
                4 /* Num */ => 7,
            },
        },
        // State 7
        LR1State {
            actions: collection! {
                0 /* '<$>' */ => LRAction::Reduce(1 /*ItemsList*/, 4),
                5 /* ',' */ => LRAction::Reduce(1 /*ItemsList*/, 4),
            },
            gotos: collection! {},
        },
    ])
});

pub const PRODUCTIONS: &[LRProduction; 7] = &[
    // 0 - List: ListOpt /* Option */;
    LRProduction { lhs: 2, len: 1 },
    // 1 - ListOpt: Items : crate::list_grammar::Numbers ;
    LRProduction { lhs: 3, len: 1 },
    // 2 - ListOpt: ;
    LRProduction { lhs: 3, len: 0 },
    // 3 - Items: Num ItemsList /* Vec */;
    LRProduction { lhs: 0, len: 2 },
    // 4 - ItemsList: ItemsList ','^ /* Clipped */ Num;
    LRProduction { lhs: 1, len: 3 },
    // 5 - ItemsList: ;
    LRProduction { lhs: 1, len: 0 },
    // 6 - Num: /0|[1-9][0-9]*/;
    LRProduction { lhs: 4, len: 1 },
];

static TOKENIZERS: Lazy<Vec<(&'static str, Tokenizer)>> = Lazy::new(|| {
    vec![(
        "INITIAL",
        Tokenizer::build(TERMINALS, SCANNER_0.0, SCANNER_0.1).unwrap(),
    )]
});

pub fn parse<'t, T>(
    input: &'t str,
    file_name: T,
    user_actions: &mut ListGrammar,
) -> Result<ParseTree<'t>, ParolError>
where
    T: AsRef<Path>,
{
    let mut lr_parser = LRParser::new(2, &PARSE_TABLE, PRODUCTIONS, TERMINAL_NAMES, NON_TERMINALS);
    lr_parser.trim_parse_tree();

    // Initialize wrapper
    let mut user_actions = ListGrammarAuto::new(user_actions);
    lr_parser.parse(
        TokenStream::new(input, file_name, &TOKENIZERS, 1).unwrap(),
        &mut user_actions,
    )
}
